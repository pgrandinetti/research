{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embeddings1.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMumYuX6u+Jp1ShF19ZYDH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymweAHcOax7S",
        "colab_type": "code",
        "outputId": "abc34bc5-f30d-4574-c585-3c43bbeb5f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lJido91a6y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [\n",
        "'They do not play games.',\n",
        "'She do not enjoy movies.',\n",
        "'You do not like politics.',\n",
        "'We do not eat meat.'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykHvn8IsbjHR",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPNFIH-GdUm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1E5QUygUA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def left_space(current, window_size):\n",
        "    # How much space is there on the left of the current position\n",
        "    # given the window size ?\n",
        "    if current >= window_size:\n",
        "        return window_size\n",
        "    else:\n",
        "        return current\n",
        "\n",
        "def right_space(current, sent_length, window_size):\n",
        "    # How much space is there on the right of the current position\n",
        "    # given the window size and the sentence total length?\n",
        "    if current >= sent_length - window_size:\n",
        "        return sent_length - current - 1\n",
        "    else:\n",
        "        return window_size\n",
        "\n",
        "def create_dataset(corpus, window_size):\n",
        "    # Create word mapping to int\n",
        "    word2Ind = {}\n",
        "    count = 0\n",
        "    sentences = []\n",
        "    for line in corpus:\n",
        "        sent = preprocess_sentence(line)\n",
        "        sentences.append(sent)\n",
        "        for token in sent.split():\n",
        "            if not token in word2Ind:\n",
        "                word2Ind[token] = count\n",
        "                count += 1\n",
        "    \n",
        "    # Create traninig set with sliding window\n",
        "    samples = []\n",
        "    for sentence in sentences:\n",
        "        sent = sentence.split()\n",
        "\n",
        "        for i, w in enumerate(sent):\n",
        "            # Get ID of center word\n",
        "            center = word2Ind[w]\n",
        "\n",
        "            # Compute how many words there are at the left of the center\n",
        "            left = left_space(i, window_size)\n",
        "\n",
        "            # Compute how many words there are at the right of the center\n",
        "            right = right_space(i, len(sent), window_size)\n",
        "\n",
        "            # Loop over the left-context\n",
        "            for l in np.arange(1, left+1):\n",
        "                # Get ID of this word\n",
        "                idx_ = word2Ind[sent[i-l]]\n",
        "                # add sample\n",
        "                samples.append([center, idx_])\n",
        "\n",
        "            # Do same for the right-context\n",
        "            for r in np.arange(1, right+1):\n",
        "                idx_ = word2Ind[sent[i+r]]\n",
        "                samples.append([center, idx_])\n",
        "    \n",
        "    # Reverse the word2Ind dictionary\n",
        "    ind2Word = {v: k for k, v in word2Ind.items()}\n",
        "\n",
        "    return word2Ind, samples, ind2Word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zxi9Y1aizc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility fn to visualize all pairs in the training set\n",
        "def show_samples(samples, ind2Word):\n",
        "    for sample in samples:\n",
        "        print(f'{ind2Word[sample[0]]} ---> {ind2Word[sample[1]]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcTYIHQ5ihc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the dataset and the dictionary word->index, index->word\n",
        "\n",
        "window_size = 1 # 1 on the left and 1 on the right\n",
        "word2Ind, samples, ind2Word = create_dataset(corpus, window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwXQBMvNiu03",
        "colab_type": "code",
        "outputId": "fa6ac2fc-976a-4ce8-b2a4-924ce4c3a771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# look at all pairs in the dataset\n",
        "show_samples(samples, ind2Word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> ---> they\n",
            "they ---> <start>\n",
            "they ---> do\n",
            "do ---> they\n",
            "do ---> not\n",
            "not ---> do\n",
            "not ---> play\n",
            "play ---> not\n",
            "play ---> games\n",
            "games ---> play\n",
            "games ---> .\n",
            ". ---> games\n",
            ". ---> <end>\n",
            "<end> ---> .\n",
            "<start> ---> she\n",
            "she ---> <start>\n",
            "she ---> do\n",
            "do ---> she\n",
            "do ---> not\n",
            "not ---> do\n",
            "not ---> enjoy\n",
            "enjoy ---> not\n",
            "enjoy ---> movies\n",
            "movies ---> enjoy\n",
            "movies ---> .\n",
            ". ---> movies\n",
            ". ---> <end>\n",
            "<end> ---> .\n",
            "<start> ---> you\n",
            "you ---> <start>\n",
            "you ---> do\n",
            "do ---> you\n",
            "do ---> not\n",
            "not ---> do\n",
            "not ---> like\n",
            "like ---> not\n",
            "like ---> politics\n",
            "politics ---> like\n",
            "politics ---> .\n",
            ". ---> politics\n",
            ". ---> <end>\n",
            "<end> ---> .\n",
            "<start> ---> we\n",
            "we ---> <start>\n",
            "we ---> do\n",
            "do ---> we\n",
            "do ---> not\n",
            "not ---> do\n",
            "not ---> eat\n",
            "eat ---> not\n",
            "eat ---> meat\n",
            "meat ---> eat\n",
            "meat ---> .\n",
            ". ---> meat\n",
            ". ---> <end>\n",
            "<end> ---> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3oBjwaPc_br",
        "colab_type": "text"
      },
      "source": [
        "## Optimization algorithm\n",
        "\n",
        "This is a very basic implementation of gradient descent, for the sake of illustration.\n",
        "\n",
        "The gradient is computed by using tensorflow's GradientTape object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPsUkLddsxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomly initialize a d-dimensional vector of real numbers\n",
        "def init_vec(d):\n",
        "    v = np.random.uniform(size=d)\n",
        "    v /= v.sum()\n",
        "    return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWHSzy25d3FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_theta(V, d):\n",
        "    '''\n",
        "    :param V: size of the vocabulary (num of words)\n",
        "    :param d: dimensionality of the embeddings\n",
        "\n",
        "    :return theta: Matrix with all vectors u,v. Even indices (0, 2, 4) are for the u.\n",
        "    '''\n",
        "    theta = np.zeros((2*V, d), dtype='float')\n",
        "    for i in range(2*V):\n",
        "        theta[i:] = init_vec(d)\n",
        "    return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEC9IGjwgq5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings dimensionality\n",
        "d = 10\n",
        "# Num of words in vocabulary\n",
        "V = len(word2Ind)\n",
        "\n",
        "# Initial condition for GD\n",
        "theta = init_theta(V, d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DeRr5mDjUp-",
        "colab_type": "code",
        "outputId": "537cc063-2173-47ae-d632-f10c36c955c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "## Check some data before optimizing\n",
        "# Will notice that as of now embeddings are just random real numbers.\n",
        "center = 2\n",
        "test = 3\n",
        "print(f'Center is \"{ind2Word[center]}\", test is \"{ind2Word[test]}\"')\n",
        "print(tf.exp(tf.tensordot(theta[center*2+1], theta[test*2], 1)))\n",
        "for i in range(len(word2Ind)):\n",
        "    print(f'Test word {i}={ind2Word[i]} >>', tf.exp(tf.tensordot(theta[center*2+1], theta[i*2], 1)))\n",
        "print('\\n')\n",
        "center = 6\n",
        "test = 7\n",
        "print(f'Center is \"{ind2Word[center]}\", test is \"{ind2Word[test]}\"')\n",
        "print(tf.exp(tf.tensordot(theta[center*2+1], theta[test*2], 1)))\n",
        "for i in range(len(word2Ind)):\n",
        "    print(f'Test word {i}={ind2Word[i]} >>', tf.exp(tf.tensordot(theta[center*2+1], theta[i*2], 1)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Center is \"do\", test is \"not\"\n",
            "tf.Tensor(1.116146169619466, shape=(), dtype=float64)\n",
            "Test word 0=<start> >> tf.Tensor(1.1288971789500877, shape=(), dtype=float64)\n",
            "Test word 1=they >> tf.Tensor(1.1071297588475966, shape=(), dtype=float64)\n",
            "Test word 2=do >> tf.Tensor(1.0956330843438067, shape=(), dtype=float64)\n",
            "Test word 3=not >> tf.Tensor(1.116146169619466, shape=(), dtype=float64)\n",
            "Test word 4=play >> tf.Tensor(1.0905545227921793, shape=(), dtype=float64)\n",
            "Test word 5=games >> tf.Tensor(1.1071061567928535, shape=(), dtype=float64)\n",
            "Test word 6=. >> tf.Tensor(1.0999922273865987, shape=(), dtype=float64)\n",
            "Test word 7=<end> >> tf.Tensor(1.0823367373518211, shape=(), dtype=float64)\n",
            "Test word 8=she >> tf.Tensor(1.1132202869717551, shape=(), dtype=float64)\n",
            "Test word 9=enjoy >> tf.Tensor(1.0931868886201406, shape=(), dtype=float64)\n",
            "Test word 10=movies >> tf.Tensor(1.1054280115514683, shape=(), dtype=float64)\n",
            "Test word 11=you >> tf.Tensor(1.1085722458218914, shape=(), dtype=float64)\n",
            "Test word 12=like >> tf.Tensor(1.1221265734130785, shape=(), dtype=float64)\n",
            "Test word 13=politics >> tf.Tensor(1.1075488268359415, shape=(), dtype=float64)\n",
            "Test word 14=we >> tf.Tensor(1.0993974247747675, shape=(), dtype=float64)\n",
            "Test word 15=eat >> tf.Tensor(1.1008740289060956, shape=(), dtype=float64)\n",
            "Test word 16=meat >> tf.Tensor(1.1136024959532387, shape=(), dtype=float64)\n",
            "\n",
            "\n",
            "Center is \".\", test is \"<end>\"\n",
            "tf.Tensor(1.1044781124352534, shape=(), dtype=float64)\n",
            "Test word 0=<start> >> tf.Tensor(1.119210261397283, shape=(), dtype=float64)\n",
            "Test word 1=they >> tf.Tensor(1.1044349706504555, shape=(), dtype=float64)\n",
            "Test word 2=do >> tf.Tensor(1.100818451062435, shape=(), dtype=float64)\n",
            "Test word 3=not >> tf.Tensor(1.1079266027415995, shape=(), dtype=float64)\n",
            "Test word 4=play >> tf.Tensor(1.101679566386083, shape=(), dtype=float64)\n",
            "Test word 5=games >> tf.Tensor(1.106721168247565, shape=(), dtype=float64)\n",
            "Test word 6=. >> tf.Tensor(1.0977633102916085, shape=(), dtype=float64)\n",
            "Test word 7=<end> >> tf.Tensor(1.1044781124352534, shape=(), dtype=float64)\n",
            "Test word 8=she >> tf.Tensor(1.0989894267318663, shape=(), dtype=float64)\n",
            "Test word 9=enjoy >> tf.Tensor(1.103294737923197, shape=(), dtype=float64)\n",
            "Test word 10=movies >> tf.Tensor(1.1075491014419074, shape=(), dtype=float64)\n",
            "Test word 11=you >> tf.Tensor(1.09506832545193, shape=(), dtype=float64)\n",
            "Test word 12=like >> tf.Tensor(1.118151326138754, shape=(), dtype=float64)\n",
            "Test word 13=politics >> tf.Tensor(1.109579571210375, shape=(), dtype=float64)\n",
            "Test word 14=we >> tf.Tensor(1.1077500548227384, shape=(), dtype=float64)\n",
            "Test word 15=eat >> tf.Tensor(1.1071401272276504, shape=(), dtype=float64)\n",
            "Test word 16=meat >> tf.Tensor(1.1151381915999103, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbOT6r6DT8bw",
        "colab_type": "text"
      },
      "source": [
        "The cost function is\n",
        "\n",
        "$$\n",
        "J(\\Theta) =\n",
        "\\min_{\\Theta(u,v)} -\\frac{1}{T} \\sum_{i=1}^{T} \\sum_{j \\in W(i)} \\log \\frac{\\text{exp}(u_j^T v_i)}{\\sum_{k \\in W} \\exp (u_k^T v_i)} =\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\min_{\\Theta(u,v)} -\\frac{1}{T} \\sum_{s \\in \\mathbf{S}} \\log \\frac{\\text{exp}(u_{s_1}^T v_{s_0})}{\\sum_{k \\in W} \\exp (u_k^T v_{s_0})}, \\, \\text{where}\\, s = [s_0, s_1]\n",
        "$$\n",
        "\n",
        "The vectors $u$ and $v$ are the embeddings for each word, in case it's the center word ($u$) or a context word ($v$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFOHI158g-0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_numerator(i, j, theta):\n",
        "    '''\n",
        "    Compute numerator of the final term of the objetive function.\n",
        "\n",
        "    :param i: Is the row-index, in Theta, of the center word.\n",
        "    :param j: Is the row-index, in Theta, of the context word.\n",
        "    :param theta: Algorithm parameters.\n",
        "    '''\n",
        "    # Theta stacks all u and v vectors.\n",
        "    # [u_0; v_0; u_1; v_1; ...; u_2*i; v2*i]\n",
        "    # Hence u_j is at row 2*j\n",
        "    # v_i is at row 2*i + 1\n",
        "    return tf.exp(tf.tensordot(theta[2*j], theta[2*i + 1], 1))\n",
        "\n",
        "\n",
        "def compute_denominator(i, theta):\n",
        "    '''\n",
        "    Compute the denominator of the sofmax when the center word is i.\n",
        "    '''\n",
        "    # Must use TF objects to differentiate.\n",
        "    tot = tf.convert_to_tensor(0., dtype='float64')\n",
        "\n",
        "    # Loop through all u's vectors\n",
        "    # Hence through Theta with step 2, starting from zero.\n",
        "    for w in np.arange(0, theta.shape[0], 2):\n",
        "        tot += tf.exp(tf.tensordot(theta[w], theta[2*i + 1], 1))\n",
        "    return tot\n",
        "\n",
        "\n",
        "def loss_element(i, j, theta):\n",
        "    '''\n",
        "    Compute one element of the total sum that makes the objective function.\n",
        "    That means, for a single sample s = [i, j]\n",
        "\n",
        "    :param i: First item of the current sample. Also, word2Ind of the first word in the sample (center word).\n",
        "    :param j: Second item of the current sample. Also, word2Ind of the second word in the sample.\n",
        "    '''\n",
        "    denom = compute_denominator(i, theta)\n",
        "    numer = compute_numerator(i, j, theta)\n",
        "    return tf.math.log(numer / denom)\n",
        "\n",
        "\n",
        "def loss_total(theta, samples):\n",
        "    '''\n",
        "    Compute the overall loss for the current value of the parameters.\n",
        "\n",
        "    :param theta: The algorithm parameters.\n",
        "    :param samples: List of lists with the shifting windows for training.\n",
        "    '''\n",
        "    loss = tf.convert_to_tensor(0., dtype='float64')\n",
        "    with tf.GradientTape() as gt:\n",
        "        gt.watch(theta)\n",
        "        for sample in samples:\n",
        "            i = sample[0] # this is always the center word\n",
        "            j = sample[1]\n",
        "            loss -= loss_element(i, j, theta)\n",
        "        loss /= len(samples)  # 1/T\n",
        "    dTheta = gt.gradient(loss, theta)\n",
        "    return loss, dTheta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bFjD29FT6qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad_desc(x0, samples, fn, lr, iterations=200):\n",
        "    '''\n",
        "    Very basic implementation of gradient descent.\n",
        "\n",
        "    :param x0: Initial condition (Theta).\n",
        "    :param samples: List of training samples.\n",
        "    :param fn: Function to compute current loss and gradient.\n",
        "    :param lr: Learning rate (constant).\n",
        "    :param iter: Number of iterations.\n",
        "    '''\n",
        "\n",
        "    losses = np.zeros((iterations,), dtype='float32')\n",
        "\n",
        "    var = tf.convert_to_tensor(x0)\n",
        "    for n in range(iterations):\n",
        "        loss, dTheta = fn(var, samples)\n",
        "        losses[n] = loss\n",
        "        print(f'Epoch {n}, loss {loss.numpy()}')\n",
        "        var = var - (lr * dTheta / np.linalg.norm(dTheta))\n",
        "\n",
        "    return var, losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuoKm_Ikb1Qt",
        "colab_type": "code",
        "outputId": "33868f32-2a24-49ca-be3d-390c5e5be8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "theta_opt, losses = grad_desc(theta, samples, loss_total, 0.2, iterations=100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss 2.832354799216204\n",
            "Epoch 1, loss 2.817975410019655\n",
            "Epoch 2, loss 2.8029208497187943\n",
            "Epoch 3, loss 2.786414700888424\n",
            "Epoch 4, loss 2.7679671112308144\n",
            "Epoch 5, loss 2.7473155253354578\n",
            "Epoch 6, loss 2.7243384030577684\n",
            "Epoch 7, loss 2.6989992283639235\n",
            "Epoch 8, loss 2.671317734478463\n",
            "Epoch 9, loss 2.641356607931803\n",
            "Epoch 10, loss 2.609216221217832\n",
            "Epoch 11, loss 2.5750335506454216\n",
            "Epoch 12, loss 2.538983239470636\n",
            "Epoch 13, loss 2.501279473277997\n",
            "Epoch 14, loss 2.4621774552187063\n",
            "Epoch 15, loss 2.4219730904885717\n",
            "Epoch 16, loss 2.380999249864169\n",
            "Epoch 17, loss 2.3396169882819153\n",
            "Epoch 18, loss 2.298200728331357\n",
            "Epoch 19, loss 2.2571179490671396\n",
            "Epoch 20, loss 2.2167061279253804\n",
            "Epoch 21, loss 2.1772515783739688\n",
            "Epoch 22, loss 2.138974953584641\n",
            "Epoch 23, loss 2.102025657067379\n",
            "Epoch 24, loss 2.0664830418281066\n",
            "Epoch 25, loss 2.0323590235041022\n",
            "Epoch 26, loss 1.9995983436359432\n",
            "Epoch 27, loss 1.9680799395688628\n",
            "Epoch 28, loss 1.9376292450289994\n",
            "Epoch 29, loss 1.9080468569815632\n",
            "Epoch 30, loss 1.8791448003076627\n",
            "Epoch 31, loss 1.8507736701242832\n",
            "Epoch 32, loss 1.8228318442336644\n",
            "Epoch 33, loss 1.7952607250132075\n",
            "Epoch 34, loss 1.7680346400424793\n",
            "Epoch 35, loss 1.7411512184266602\n",
            "Epoch 36, loss 1.7146240976366782\n",
            "Epoch 37, loss 1.6884777094811072\n",
            "Epoch 38, loss 1.6627434108326102\n",
            "Epoch 39, loss 1.6374564375532115\n",
            "Epoch 40, loss 1.6126534865279418\n",
            "Epoch 41, loss 1.5883709377903217\n",
            "Epoch 42, loss 1.56464375962813\n",
            "Epoch 43, loss 1.5415050208713843\n",
            "Epoch 44, loss 1.5189857456526767\n",
            "Epoch 45, loss 1.4971146977923195\n",
            "Epoch 46, loss 1.4759176807153358\n",
            "Epoch 47, loss 1.4554161378284622\n",
            "Epoch 48, loss 1.4356251977977788\n",
            "Epoch 49, loss 1.4165516867605048\n",
            "Epoch 50, loss 1.3981928250889826\n",
            "Epoch 51, loss 1.3805361882473655\n",
            "Epoch 52, loss 1.3635610581778164\n",
            "Epoch 53, loss 1.3472407462735245\n",
            "Epoch 54, loss 1.331545129388603\n",
            "Epoch 55, loss 1.3164426674105414\n",
            "Epoch 56, loss 1.3019014883906537\n",
            "Epoch 57, loss 1.2878895216209592\n",
            "Epoch 58, loss 1.2743739538915106\n",
            "Epoch 59, loss 1.2613204234266482\n",
            "Epoch 60, loss 1.248692379672395\n",
            "Epoch 61, loss 1.2364509687404424\n",
            "Epoch 62, loss 1.224555673761268\n",
            "Epoch 63, loss 1.2129657546936738\n",
            "Epoch 64, loss 1.2016423200060549\n",
            "Epoch 65, loss 1.19055068052741\n",
            "Epoch 66, loss 1.1796625496823068\n",
            "Epoch 67, loss 1.1689576985935657\n",
            "Epoch 68, loss 1.1584248279449931\n",
            "Epoch 69, loss 1.148061617240898\n",
            "Epoch 70, loss 1.1378740861423329\n",
            "Epoch 71, loss 1.1278755059432324\n",
            "Epoch 72, loss 1.1180851189275933\n",
            "Epoch 73, loss 1.1085268721311432\n",
            "Epoch 74, loss 1.0992282776358997\n",
            "Epoch 75, loss 1.0902194076804432\n",
            "Epoch 76, loss 1.0815319522314832\n",
            "Epoch 77, loss 1.073198234172928\n",
            "Epoch 78, loss 1.0652501031229646\n",
            "Epoch 79, loss 1.0577177006740823\n",
            "Epoch 80, loss 1.0506281676519313\n",
            "Epoch 81, loss 1.0440043927893596\n",
            "Epoch 82, loss 1.0378638559395639\n",
            "Epoch 83, loss 1.0322175507152054\n",
            "Epoch 84, loss 1.0270689899125118\n",
            "Epoch 85, loss 1.022413438130252\n",
            "Epoch 86, loss 1.0182376538702358\n",
            "Epoch 87, loss 1.0145203896119959\n",
            "Epoch 88, loss 1.011233682327717\n",
            "Epoch 89, loss 1.0083447193738362\n",
            "Epoch 90, loss 1.0058185383208185\n",
            "Epoch 91, loss 1.003705992988969\n",
            "Epoch 92, loss 1.0090252798278565\n",
            "Epoch 93, loss 1.003829778508263\n",
            "Epoch 94, loss 1.0083433085156177\n",
            "Epoch 95, loss 1.0034927565238134\n",
            "Epoch 96, loss 1.0077687126698622\n",
            "Epoch 97, loss 1.003204204636387\n",
            "Epoch 98, loss 1.0073210877247731\n",
            "Epoch 99, loss 1.0029869459368783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP_uZ6y9d3vE",
        "colab_type": "code",
        "outputId": "1f9d562b-7ce8-48bf-d348-164944066e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Look at the whole loss function during the optimization\n",
        "intv = np.arange(0, len(losses))\n",
        "_ = plt.plot(intv, losses[intv])\n",
        "_ = plt.xlabel('Optimization step')\n",
        "_ = plt.ylabel('Loss')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCggREYlKASEiIlEpIEREJKr/D6YoIRN1sbe4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nEDgAhPfWxR",
        "colab_type": "code",
        "outputId": "8f66545b-694c-475f-e486-afc5c64dffd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Zoom in the loss during the final optimization steps\n",
        "intv = np.arange(80, len(losses))\n",
        "_ = plt.plot(intv, losses[intv])\n",
        "_ = plt.xlabel('Optimization step')\n",
        "_ = plt.ylabel('Loss')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWVMuYp+adEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0gcpgvaJZNh",
        "colab_type": "text"
      },
      "source": [
        "The oscillations are a sign that we've got to stop the iterative procedure. It would possible to improve it by changing some hyperparameter (such as the learning rate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHIM4q-fdvJ",
        "colab_type": "text"
      },
      "source": [
        "## Show some samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPG-vSczordJ",
        "colab_type": "code",
        "outputId": "55c885e7-bf0a-45a5-92c4-8e999813bf62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "## Check some data after optimizing\n",
        "# Will notice that the dot product is now much higher for the context words than for the others, for each given center word\n",
        "center = 2\n",
        "test = 3\n",
        "print(f'Center is \"{ind2Word[center]}\", test is \"{ind2Word[test]}\"')\n",
        "print(tf.exp(tf.tensordot(theta_opt[center*2+1], theta_opt[test*2], 1)))\n",
        "for i in range(len(word2Ind)):\n",
        "    print(f'Test word {i}={ind2Word[i]} >>', tf.exp(tf.tensordot(theta_opt[center*2+1], theta_opt[i*2], 1)))\n",
        "print('\\n')\n",
        "center = 6\n",
        "test = 7\n",
        "print(f'Center is \"{ind2Word[center]}\", test is \"{ind2Word[test]}\"')\n",
        "print(tf.exp(tf.tensordot(theta_opt[center*2+1], theta_opt[test*2], 1)))\n",
        "for i in range(len(word2Ind)):\n",
        "    print(f'Test word {i}={ind2Word[i]} >>', tf.exp(tf.tensordot(theta_opt[center*2+1], theta_opt[i*2], 1)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Center is \"do\", test is \"not\"\n",
            "tf.Tensor(265.47320718665674, shape=(), dtype=float64)\n",
            "Test word 0=<start> >> tf.Tensor(0.31829067616650725, shape=(), dtype=float64)\n",
            "Test word 1=they >> tf.Tensor(96.39118135113179, shape=(), dtype=float64)\n",
            "Test word 2=do >> tf.Tensor(0.07839746275724133, shape=(), dtype=float64)\n",
            "Test word 3=not >> tf.Tensor(265.47320718665674, shape=(), dtype=float64)\n",
            "Test word 4=play >> tf.Tensor(0.18064613586322822, shape=(), dtype=float64)\n",
            "Test word 5=games >> tf.Tensor(0.3686308526571574, shape=(), dtype=float64)\n",
            "Test word 6=. >> tf.Tensor(0.07539733403450666, shape=(), dtype=float64)\n",
            "Test word 7=<end> >> tf.Tensor(0.018871837503493753, shape=(), dtype=float64)\n",
            "Test word 8=she >> tf.Tensor(96.34016252586977, shape=(), dtype=float64)\n",
            "Test word 9=enjoy >> tf.Tensor(0.019857738915322647, shape=(), dtype=float64)\n",
            "Test word 10=movies >> tf.Tensor(0.3100757746416495, shape=(), dtype=float64)\n",
            "Test word 11=you >> tf.Tensor(96.50989558451292, shape=(), dtype=float64)\n",
            "Test word 12=like >> tf.Tensor(0.07869309499908729, shape=(), dtype=float64)\n",
            "Test word 13=politics >> tf.Tensor(0.49626054421077886, shape=(), dtype=float64)\n",
            "Test word 14=we >> tf.Tensor(96.37172527931939, shape=(), dtype=float64)\n",
            "Test word 15=eat >> tf.Tensor(0.033494225834981795, shape=(), dtype=float64)\n",
            "Test word 16=meat >> tf.Tensor(0.3012141463330023, shape=(), dtype=float64)\n",
            "\n",
            "\n",
            "Center is \".\", test is \"<end>\"\n",
            "tf.Tensor(274.92931730696154, shape=(), dtype=float64)\n",
            "Test word 0=<start> >> tf.Tensor(0.08588802716852414, shape=(), dtype=float64)\n",
            "Test word 1=they >> tf.Tensor(0.05786111430850685, shape=(), dtype=float64)\n",
            "Test word 2=do >> tf.Tensor(0.04322374740322572, shape=(), dtype=float64)\n",
            "Test word 3=not >> tf.Tensor(0.39507544095426916, shape=(), dtype=float64)\n",
            "Test word 4=play >> tf.Tensor(0.11273540032063183, shape=(), dtype=float64)\n",
            "Test word 5=games >> tf.Tensor(68.74444147080102, shape=(), dtype=float64)\n",
            "Test word 6=. >> tf.Tensor(0.08634527179918267, shape=(), dtype=float64)\n",
            "Test word 7=<end> >> tf.Tensor(274.92931730696154, shape=(), dtype=float64)\n",
            "Test word 8=she >> tf.Tensor(0.06846548657072914, shape=(), dtype=float64)\n",
            "Test word 9=enjoy >> tf.Tensor(0.37378816394006187, shape=(), dtype=float64)\n",
            "Test word 10=movies >> tf.Tensor(68.6405019060012, shape=(), dtype=float64)\n",
            "Test word 11=you >> tf.Tensor(0.06454379179761699, shape=(), dtype=float64)\n",
            "Test word 12=like >> tf.Tensor(0.06686752998414455, shape=(), dtype=float64)\n",
            "Test word 13=politics >> tf.Tensor(68.80146901636705, shape=(), dtype=float64)\n",
            "Test word 14=we >> tf.Tensor(0.0640831898828426, shape=(), dtype=float64)\n",
            "Test word 15=eat >> tf.Tensor(0.195159974968725, shape=(), dtype=float64)\n",
            "Test word 16=meat >> tf.Tensor(68.6821280228963, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}